
import os
import pandas as pd
import streamlit as st
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_community.chat_models import ErnieBotChat
from langchain_community.embeddings import ErnieEmbeddings
from langchain_community.vectorstores import Qdrant
from langchain_community.document_loaders import PyPDFLoader,Docx2txtLoader,TextLoader
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain_community.document_transformers import LongContextReorder
from langchain.text_splitter import RecursiveCharacterTextSplitter
import json
import re
from langchain_community.llms import Tongyi
from langchain_community.llms import SparkLLM
from langchain_community.llms import OpenAI
# from langchain_community.llms import ChatZhipuAI
from langchain_community.llms.moonshot import Moonshot
from langchain_community.embeddings import DashScopeEmbeddings
from langchain_community.embeddings import SparkLLMTextEmbeddings
from langchain_community.embeddings.openai import OpenAIEmbeddings
from langchain_community.embeddings import OpenAIEmbeddings
import warnings
warnings.filterwarnings("ignore")
# deprecation_warning(message, category=Warning, stacklevel=2)
#-----------------------æ¨¡å‹å‡†å¤‡------------------------

# è¯»å–API Keyé…ç½®æ–‡ä»¶
# with open(r"é˜…è¯»å°åŠ©æ‰‹\api_config.json") as f:
#     api_key = json.load(f)
api_key = {"API Key":"cqbB6Wqoxoh6v31L77SE97gf",
"Secret Key":"AJuOX2qe7FwOoSIjSlONr4COFpbzZ2OZ",
 "DASHSCOPE_API_KEY":"sk-8f84e7856c404659a69842fb9fafce73",
"serpapi_api_key":"80eb2e013508e5f8fe9a9a1915486403165108d396cd5fa337a0c81dc75be2da",
"APISecret":"NGNkYjAwYzkzMmE4MzExYzZmMDE1MWNk",
"APIKey":"2bb963482fc186afb8cd2d9ddfcca7f6",
"APPID":"a1679b4b",
"openapi":"sk-TzztBITk5tBfZuu0epzFCuPDPUq33IPTJ5nqYY7KZMwBTW9z"}

ernie_client_id = api_key['API Key']         # æ–‡å¿ƒå¤§æ¨¡å‹ernie_client_id
ernie_client_secret = api_key['Secret Key']  # æ–‡å¿ƒå¤§æ¨¡å‹ernie_client_secret
DASHSCOPE_API_KEY = api_key['DASHSCOPE_API_KEY'] # é˜¿é‡Œé€šä¹‰åƒé—®æ¨¡å‹DASHSCOPE_API_KEY
SPARKAI_APP_ID = api_key['APPID'] #æ˜Ÿç«å¤§æ¨¡å‹id
SPARKAI_API_SECRET = api_key['APISecret']
SPARKAI_API_KEY = api_key['APIKey']
API_KEY = api_key['openapi']
# zhipu = api_key['zhipu']
llm1 = ErnieBotChat(
    model_name='ERNIE-Bot-4',
    ernie_client_id=ernie_client_id,
    ernie_client_secret=ernie_client_secret,
    temperature=1,
)
llm2 = Tongyi(temperature=1, dashscope_api_key=DASHSCOPE_API_KEY)
llm3 = SparkLLM(spark_app_id=SPARKAI_APP_ID,
        spark_api_key=SPARKAI_API_KEY,
        spark_api_secret=SPARKAI_API_SECRET,
        temperature=1)
embedding1 = ErnieEmbeddings(ernie_client_id=ernie_client_id,
                                  ernie_client_secret=ernie_client_secret)
embedding2 = DashScopeEmbeddings(
    model="text-embedding-v2", dashscope_api_key=DASHSCOPE_API_KEY
)
embedding3 = SparkLLMTextEmbeddings(spark_app_id=SPARKAI_APP_ID,spark_api_key=SPARKAI_API_KEY,spark_api_secret=SPARKAI_API_SECRET)
# -----------------------æ•°æ®è¯»å–ã€åˆ‡åˆ†ã€å‘é‡åŒ–ã€é—®ç­”ç­‰å‡½æ•°------------------------

def load_document(file):
    '''
    å¯¼å…¥æ–‡æ¡£ï¼Œæ”¯æŒ PDF, DOCX and TXT æ–‡ä»¶
    :param file: æ–‡ä»¶è·¯å¾„
    :return: æ–‡æœ¬æ•°æ®
    '''
    name, extension = os.path.splitext(file)
    if extension == '.pdf':
        loader = PyPDFLoader(file)
        documents = loader.load()
    elif extension == '.docx':
        loader = Docx2txtLoader(file)
        documents = loader.load()
    elif extension == '.txt':
        try:
            loader = TextLoader(file, encoding='utf8')
            documents = loader.load()
        except:
            loader = TextLoader(file, encoding='gbk')
            documents = loader.load()
    else:
        st.error('ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œä»…æ”¯æŒPDFã€DOCXã€TXTæ–‡ä»¶')
        documents = ''
    # æ–‡æ¡£é¢„å¤„ç†
    documents[0].page_content = re.sub(r'\n{2,}', '\n', documents[0].page_content)
    documents[0].page_content = re.sub(r'\t', '', documents[0].page_content)
    return documents

def create_embeddings(documents, embedding):
    '''
    æ–‡æ¡£å‘é‡åŒ–å’Œå­˜å‚¨
    :param documents: åˆ‡åˆ†å¥½çš„æ–‡æ¡£
    :param embedding: å‘é‡åŒ–æ¨¡å‹
    :return: å‘é‡åŒ–å­˜å‚¨çš„å¯¹è±¡
    '''
    vectorstore = Qdrant.from_documents(
        documents=documents,
        embedding=embedding,
        location=':memory:',
        collection_name='my_documents')
    return vectorstore
def chunk_data(data, file_name='a.txt', chunk_size=256, chunk_overlap=100):
    '''
    æ–‡æ¡£åˆ‡åˆ†
    :param data: å¾…åˆ‡åˆ†çš„æ–‡æ¡£
    :param file_name: æ–‡ä»¶å
    :param chunk_size: åˆ‡å—å¤§å°
    :param chunk_overlap: åˆ‡å—é‡å å¤§å°
    :return: åˆ‡åˆ†åçš„æ–‡æ¡£å¯¹è±¡
    '''
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)
    chunks = text_splitter.split_documents(data)
    file_name = file_name.split('.')[0] # å»é™¤æ–‡ä»¶ååç¼€
    for i in chunks: # ç»™æ¯ä¸ªåˆ†å—æ·»åŠ å¯¹äºçš„æ¥æºæ–‡ä»¶åï¼Œä¾¿äºæ£€ç´¢æ›´ç²¾ç¡®
        i.page_content = file_name+'.'+i.page_content
    return chunks


# æ¸…ç©ºå¯¹è¯è®°å½•
def clear_chat_history():
    '''
    æ¸…ç©ºå¯¹è¯è®°å½•
    :return:
    '''
    if 'messages' in st.session_state:
        del st.session_state['messages']

def clear_embedding():
    '''
    æ¸…ç©ºçŸ¥è¯†åº“å’Œæ–‡æ¡£
    :return:
    '''
    for i in st.session_state.filenames: # åˆ é™¤ä¿å­˜çš„æ–‡ä»¶
        try:
            delfile = os.path.join('./', i)
            os.remove(delfile)
        except:
            pass
    st.session_state.vs = [] # æ¸…ç©ºå‘é‡
    st.session_state.filenames = [] # æ¸…ç©ºä¿å­˜çš„æ–‡ä»¶å
    st.info('çŸ¥è¯†åº“å·²æ¸…ç©ºï¼Œå¯ä»¥æ–°å¢çŸ¥è¯†åº“åç»§ç»­ã€‚')
    global file_name
    try:
        del file_name # åˆ é™¤æ–‡ä»¶åå˜é‡
    except:
        pass

def format_docs(docs):
    '''
    å°†è¿”å›çš„æ–‡æ¡£page_contentçš„å†…å®¹æ‹¼æ¥ä¸ºå­—ç¬¦ä¸²ï¼Œå‡å°‘å…¶ä»–ä¿¡æ¯å¹²æ‰°
    :param docs: æ–‡æ¡£å¯¹è±¡
    :return: æ‹¼æ¥åçš„å­—ç¬¦ä¸²
    '''
    reordering = LongContextReorder() # å®ä¾‹åŒ–å¯¹è±¡
    reordered_docs = reordering.transform_documents(docs) # æ–‡æ¡£é‡æ’
    # æ–‡æ¡£é‡æ’åï¼Œå°†å†…å®¹æ‹¼æ¥ä¸ºå­—ç¬¦ä¸²è¾“å‡º
    return "\n\n".join([doc.page_content for doc in reordered_docs])
def ask_and_get_answer(llm, ask, vector_store, k=3):
    '''
    é—®ç­”å‡½æ•°
    :param llm: å¤§æ¨¡å‹
    :param ask: é—®é¢˜
    :param vector_store: å‘é‡åŒ–å­˜å‚¨çš„å¯¹è±¡
    :param k: ç›¸ä¼¼åº¦å‰kä¸ªæ–‡æ¡£
    :return: ç­”æ¡ˆ
    '''
    if st.session_state.vs != []: # è‹¥æ·»åŠ äº†çŸ¥è¯†åº“ï¼Œåˆ™æ ¹æ®çŸ¥è¯†åº“å›ç­”é—®é¢˜
        if k>3:
            retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': k})
        else:
            retriever = vector_store.as_retriever(search_type='similarity')
            retriever_from_llm = MultiQueryRetriever.from_llm(
            retriever=retriever, llm=llm)
        template = '''Answer the question based only on the following context:{context}
        Please answer the question only by chinese.
        If you can't answer the question, please say "å¯¹ä¸èµ·ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³çš„çŸ¥è¯†".
        Question:{question}
        '''
        prompt = ChatPromptTemplate.from_template(template)
        output_parser = StrOutputParser()
        chain = {"context": retriever | format_docs, "question": RunnablePassthrough()} \
                | prompt \
                | llm \
                | output_parser
        output = chain.invoke(ask)
    else: # è‹¥æ²¡æ·»åŠ çŸ¥è¯†åº“ï¼Œåˆ™æ ¹æ®å¤§æ¨¡å‹æœ¬èº«çš„è®¤çŸ¥å›ç­”é—®é¢˜
        template = '''Answer the question by chinese.
        Question:{question}
        '''
        prompt = ChatPromptTemplate.from_template(template)
        chain = {"question": RunnablePassthrough()}| prompt | llm | StrOutputParser()
        output = chain.invoke(ask) + '\n\nï¼ˆæ¸©é¦¨æç¤ºï¼šä»¥ä¸Šå›ç­”æ˜¯åŸºäºé€šç”¨æ•°æ®çš„å›ç­”ï¼Œè‹¥æƒ³åŸºäºæ–‡æ¡£å›ç­”è¯·å…ˆã€æ·»åŠ çŸ¥è¯†åº“ã€‘ï¼‰'
    return output


def convert_df():
    '''
    å°†å¯¹è¯è®°å½•è½¬æ¢ä¸ºcsvæ–‡ä»¶
    :return:
    '''
    df = pd.DataFrame(st.session_state.messages)
    df = df.applymap(lambda x: str(x).replace('\n', '').replace(',', 'ï¼Œ'))
    return df.to_csv(index=False, encoding='utf-8', mode='w', sep=',')

# # -------------------------ä¸»é¡µé¢è®¾ç½®------------------------

st.set_page_config(page_title='è®ºæ–‡é˜…è¯»åŠ©æ‰‹', page_icon=':robot:', layout='wide')
st.title('åŸºäºLangchainçš„è®ºæ–‡é˜…è¯»åŠ©æ‰‹ï¼ˆRAGï¼‰ ğŸ¤–')
st.markdown('---')

# åˆå§‹åŒ–session_stateä¸­çš„messages
if 'messages' not in st.session_state:
    st.session_state.messages = []

# åˆå§‹åŒ–çŸ¥è¯†åº“
if 'vs' not in st.session_state:
    st.session_state.vs = []

# åˆå§‹åŒ–å¯¼å…¥çš„æ–‡ä»¶å
if 'filenames' not in st.session_state:
    st.session_state.filenames = []

# æ£€æŸ¥filenamesæ˜¯å¦ä¸ºç©ºåˆ—è¡¨
if st.session_state.filenames == []:
    st.error("æ‚¨è¿˜æ²¡æœ‰æ·»åŠ ä»»ä½•æ–‡ä»¶ã€‚è¯·å…ˆæ·»åŠ æ–‡ä»¶ä»¥å¯¼å…¥çŸ¥è¯†åº“ã€‚")

# å±•ç¤ºèŠå¤©è®°å½•
for message in st.session_state.messages:
    if message["role"] == "user":
        with st.chat_message(message["role"], avatar='â˜ºï¸'):
            st.markdown(message["content"])
    else:
        with st.chat_message(message["role"], avatar='ğŸ¤–'):
            st.markdown(message["content"])

# ---------------------ä¾§è¾¹æ è®¾ç½®-----------------------

# æ–‡æ¡£ä¸Šä¼ 
st.sidebar.subheader('ä¸Šä¼ çŸ¥è¯†åº“')
uploaded_file = st.sidebar.file_uploader('æ–‡ä»¶ä¸Šä¼ :', type=['pdf', 'docx', 'txt', 'doc'])

if uploaded_file is None:
    st.error('æ³¨æ„ï¼Œå…ˆä¸Šä¼ æ–‡ä»¶-é…ç½®çŸ¥è¯†åº“ï¼')
    # st.stop()
else:
    st.sidebar.warning(f'ä¸Šä¼ æˆåŠŸï¼æ³¨æ„ã€æ·»åŠ çŸ¥è¯†åº“ã€‘')

# åˆ†å—å‚æ•°
chunk_size = st.sidebar.number_input('åˆ†å—å¤§å°:', min_value=100, max_value=2048, value=1024)
# æœç´¢æ–‡æ¡£å‚æ•°
k = st.sidebar.number_input('æœç´¢è¿”å›æ–‡æ¡£æ•°', min_value=1, max_value=100, value=10)
myllm = st.sidebar.selectbox('æ¨¡å‹é€‰æ‹©', ['é˜¿é‡Œé€šä¹‰åƒé—®', 'ç™¾åº¦æ–‡å¿ƒä¸€è¨€','è®¯é£æ˜Ÿç«'])
llm = None
embedding = None
if myllm == 'æ–‡å¿ƒä¸€è¨€':
    llm = llm1
    embedding = embedding1
elif myllm == 'é˜¿é‡Œé€šä¹‰åƒé—®':
    llm = llm2
    embedding = embedding2
elif myllm == 'è®¯é£æ˜Ÿç«':
    llm = llm3
    embedding = embedding3
else:
    pass


add_or_no = st.sidebar.radio('çŸ¥è¯†åº“ç®¡ç†', ['åˆå¹¶æ–°å¢çŸ¥è¯†åº“', 'ä»…ä½¿ç”¨å½“å‰çŸ¥è¯†åº“'])

if uploaded_file:  # if the user browsed a file
    with st.spinner('æ­£åœ¨è¯»å–æ–‡ä»¶ ...'):
        bytes_data = uploaded_file.read()

        # æ–‡ä»¶å†™å‡º
        file_name = os.path.join('./', uploaded_file.name)
        with open(file_name, 'wb') as f:
            f.write(bytes_data)
        if add_or_no == 'åˆå¹¶æ–°å¢çŸ¥è¯†åº“':
            st.session_state.filenames.append(uploaded_file.name)
        else:
            st.session_state.filenames= [uploaded_file.name]

# ---------------------å¯¹è¯æ å¯¹è¯è®¾ç½®-----------------------

if prompt := st.chat_input('è¯·è¾“å…¥ä½ çš„é—®é¢˜'):
    # è¾“å…¥é—®é¢˜
    with st.chat_message('user', avatar='â˜ºï¸'):
        st.markdown(prompt)
    # åœ¨å†å²å¯¹è¯ä¸­æ·»åŠ ç”¨æˆ·çš„é—®é¢˜
    st.session_state.messages.append({'role': 'user', 'content': prompt})
    # è°ƒç”¨å‡½æ•°ï¼Œè·å–å›ç­”
    with st.spinner('æ­£åœ¨æ£€ç´¢ï¼Œè¯·ç¨å ...'):
        response = ask_and_get_answer(llm, prompt, st.session_state.vs, k)
    # è¾“å‡ºç­”æ¡ˆ
    with st.chat_message('AI', avatar='ğŸ¤–'):
        st.markdown(response)
    # åœ¨å†å²å¯¹è¯ä¸­æ·»åŠ é—®é¢˜çš„ç­”æ¡ˆ
    st.session_state.messages.append({'role': 'AI', 'content': response})


# ---------------------å¯¹è¯æ æ¸…ç©ºå¯¹è¯ã€å¯¼å…¥çŸ¥è¯†åº“ç­‰è®¾ç½®-----------------------
col1, col2, col3, col4, _ = st.columns([1, 1,  1, 1, 1])

with col2:
    drop_embedding = st.button('æ¸…ç©ºçŸ¥è¯†åº“', use_container_width=True)
if drop_embedding:
    clear_embedding()
    st.toast(':red[çŸ¥è¯†åº“å·²æ¸…ç©ºï¼]', icon='ğŸ¤–')

with col3:
    if st.button("æ¸…é™¤å¯¹è¯å†å²", on_click=clear_chat_history, use_container_width = True):
        st.session_state["messages"] = []
        st.toast(':red[å¯¹è¯å†å²å·²æ¸…é™¤ï¼]', icon='ğŸ¤–')

with col4:
    download_button = st.download_button(label="å¯¼å‡ºå¯¹è¯è®°å½•",
                                         data=convert_df(), # å¯¼å‡ºå‡½æ•°
                                         file_name='chat_history.csv', # æ–‡ä»¶å
                                         mime='text/csv',  # æ–‡ä»¶ç±»å‹
                                         use_container_width=True)

with col1:
    add = st.button('æ·»åŠ çŸ¥è¯†åº“', use_container_width=True)
if add:
    with st.spinner("çŸ¥è¯†åº“ç”Ÿæˆä¸­..."):
        # è¯»å–æ–‡æ¡£
        data = load_document(file_name)
        #  åˆ†å‰²æ•°æ®
        chunks = chunk_data(data,file_name=file_name, chunk_size=chunk_size)
        # åˆ›å»ºçŸ¥è¯†åº“çš„åµŒå…¥å‘é‡
        vector_store = create_embeddings(chunks, embedding)
        st.toast(':red[çŸ¥è¯†åº“æ·»åŠ æˆåŠŸï¼]', icon='ğŸ¤–')
        # ä¿å­˜çŸ¥è¯†åº“
        if add_or_no == 'åˆå¹¶æ–°å¢çŸ¥è¯†åº“':
            if st.session_state.vs==[]:
                st.session_state.vs = vector_store
            else:
                st.session_state.vs.add_documents(chunks) # æ·»åŠ æ–°çš„æ–‡æ¡£
        else:
            st.session_state.vs = vector_store
        # æ·»åŠ çŸ¥è¯†åº“åç§°
        files = 'ï¼›'.join(list(set(st.session_state.filenames)))
        st.success(f'æ·»åŠ æˆåŠŸï¼å·²æœ‰çŸ¥è¯†åº“ï¼š{files}')
        if st.session_state.messages == []:
            st.session_state.messages.append({'role': 'AI', 'content': f'å·²æœ‰çŸ¥è¯†åº“ï¼š{files}'})
        else:
            st.session_state.messages[-1] = {'role': 'AI', 'content': f'å·²æœ‰çŸ¥è¯†åº“ï¼š{files}'}
        with st.chat_message('AI', avatar='ğŸ¤–'):
            st.markdown(st.session_state.messages[-1]['content'])



